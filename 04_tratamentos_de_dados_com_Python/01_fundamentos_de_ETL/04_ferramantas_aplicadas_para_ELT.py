"""
    Ferramentas utilizadas
    As ferramentas são softwares utilizados para facilitar o processo
    de integração de dados. Inicialmente muito usados em projetos de
    Data Warehouse e Business Intelligence em geral, ultimamente tem
    sido utilizados em processos de integração de software, bancos de
    dados, etc.
"""

"""
    Existem diversas ferramentas de ELT, como:
    IBM Data Stage
    Power Center
    SQL  Server Integration Services
    Talend ETL
"""

"""
    ELT para BIG Data
    Hoje com o crescimento dos projetos de Big data aumenta-se mais
    ainda mais a necessidade de fazer ETL entre plataformas heterogêneas,
    para isso, projetos como o Hadoop, possuem ferramentas próprias para
    carga de dados, como:

    SQOOP - Ferramenta para movivmentar dados entre bacnos de dados relacionais
    e o ambiente Hadoop.

    HIVE - Ambiente de SQL sobre um cluster Hadoop.

    PIG - Ferramenta de Script para transformação e processamento de dados.

    SPARK - Framework de processamento em memória.
"""

"""
    Mas o que é Hadoop?
    Hadoop é uma plataforma de software em Java de computação distribuída
    voltada para clsters e processamento de grandes volumes de dados, com
    atenção a tolerância de falhas.
"""

"""
    Mesmo com todas as possibilidades acima, vemos as ferramentas de ELT se
    adaptando para Big Data ou gerando códigos para serem rodados nessas ferramentas
    do ecosistema Hadoop.

    Em Big data, o processo de carga também é conhecido como Ingestão de Dados, que
    geralmente é a primeira parte da carga (Extract) a parte mais simples do processo,
    que consiste em extrair dados dos sistemas de origem e trazer para  dentro do Data
    Lake ou ambiente de dados utilizado.
"""